{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd1adedf",
   "metadata": {},
   "source": [
    "### **Sigmoid vs Contrastive Loss**\n",
    "Recommendation: Use SIGMOID loss for your use case. Here's why:\n",
    "\n",
    "AspectSigmoid LossContrastive Loss\n",
    "Best for Multi-label (multiple conditions per image)Single-label classification\n",
    "Your data‚úÖ 20%+ multi-label samples‚ùå Treats each sample as single class\n",
    "Output Independent probabilities per classProbability distribution (sums to 1)\n",
    "TrainingEach label trained independentlyContrasts positive vs negative pairs\n",
    "Class imbalance‚úÖ Handles better with per-class thresholds‚ùå Can struggle with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Train SigLIP with FINE-GRAINED contrastive learning.\n",
    "Uses the 66 specific condition labels with their descriptions for more precise matching.\n",
    "\n",
    "This approach should provide:\n",
    "- Better discrimination between specific conditions\n",
    "- More precise retrieval accuracy\n",
    "- Direct condition-level matching without hierarchical complexity\n",
    "\"\"\"\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "\n",
    "# Get the current timestamp\n",
    "now = datetime.now()\n",
    "\n",
    "timestamp_str = now.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoProcessor,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Model\n",
    "    model_name: str = 'google/siglip-base-patch16-224'\n",
    "    \n",
    "    # Training\n",
    "    batch_size: int = 32\n",
    "    num_epochs: int = 15\n",
    "    learning_rate: float = 1e-6\n",
    "    weight_decay: float = 0.05  # Increased this (was 1e-4). High decay prevents overfitting.\n",
    "    warmup_steps: int = 100\n",
    "    \n",
    "    #Lora parameters\n",
    "    lora_rank: int = 32\n",
    "    lora_alpha: int = 32\n",
    "\n",
    "    # Device\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    fp16: bool = torch.cuda.is_available()\n",
    "    temperature: float = 0.7\n",
    "    \n",
    "    # Set this to \"contrastive\" or \"sigmoid\"\n",
    "    loss_type: str = \"sigmoid\" # or \"contrastive\"\n",
    "    \n",
    "    # finetune_mode. # Options: \"FULL\", \"LoRA\"\n",
    "    finetune_mode: str = \"LoRA\"  \n",
    "    \n",
    "    # Data paths\n",
    "    data_dir: Path = Path('/home/agentic-health/data')\n",
    "    visual_descriptions_path: Path ='./data/condition_visual_descriptions.json'\n",
    "    metadata_file: Path = './data/coarse_labeled_metadata_with_labels.csv'\n",
    "    images_dir: Path = data_dir / 'scin/images'\n",
    "    \n",
    "    @property\n",
    "    def output_dir(self) -> Path:\n",
    "        return Path(f'./siglip_{self.loss_type.lower()}_{self.loss_type}_{timestamp_str}')\n",
    "\n",
    "config = Config()\n",
    "config.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class DualLogger:\n",
    "    def __init__(self, filepath):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filepath, \"w\") # Overwrite file each run\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message) # Write to screen\n",
    "        self.log.write(message)      # Write to file\n",
    "        self.log.flush()             # Ensure it saves immediately\n",
    "\n",
    "    def flush(self):\n",
    "        # Needed for compatibility with some libraries\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "        \n",
    "log_file_path = config.output_dir / \"training_log.txt\"\n",
    "sys.stdout = DualLogger(log_file_path)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"SIGLIP FINE-GRAINED {config.loss_type} LEARNING USLING {config.finetune_mode}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Model: {config.model_name}\")\n",
    "print(f\"  Output: {config.output_dir}\")\n",
    "print(f\"  Device: {config.device}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "print(f\"  Learning rate: {config.learning_rate}\")\n",
    "print(f\"  Epochs: {config.num_epochs}\")\n",
    "print(f\"  Lora_rank: {config.lora_rank}\")   \n",
    "print(f\"  Output directory: {config.output_dir}\")\n",
    "\n",
    "# Load data\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Loading Data\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = pd.read_csv(config.metadata_file)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Fine-grained conditions: {df['condition'].nunique()}\")\n",
    "print(f\"Coarse categories: {df['coarse_category'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b2b35afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_from_item(item):\n",
    "    \"\"\"\n",
    "        Extract label from a dataset item (dictionary row).\n",
    "        We prefer the 'description' column if available, otherwise template the condition\n",
    "    \"\"\"   \n",
    "    if pd.notna(item['description']):\n",
    "        text = item['description']\n",
    "    else:\n",
    "        # Fallback template if description is missing\n",
    "        text = f\"A dermatological photo showing {item['condition']}\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "def stratified_split_data(all_data, val_ratio=0.15, test_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Splits data while ensuring rare classes are distributed across all sets.\n",
    "    Strategy: Assigns rare classes first to ensure Val/Test coverage.\n",
    "    \"\"\"\n",
    "    train_data, val_data, test_data = [], [], []\n",
    "    \n",
    "    # 1. Map each class to its samples\n",
    "    class_to_samples = defaultdict(list)\n",
    "    sample_to_id = {} # Track assigned samples\n",
    "    \n",
    "    for idx, item in enumerate(all_data):\n",
    "        labels = get_labels_from_item(item)\n",
    "        sample_to_id[idx] = False # False = not assigned\n",
    "        for label in labels:\n",
    "            class_to_samples[label].append(idx)\n",
    "            \n",
    "    # 2. Sort classes by rarity (rarest first)\n",
    "    sorted_classes = sorted(class_to_samples.keys(), key=lambda k: len(class_to_samples[k]))\n",
    "    \n",
    "    for cls in sorted_classes:\n",
    "        indices = class_to_samples[cls]\n",
    "        # Filter for unassigned indices\n",
    "        available_indices = [i for i in indices if not sample_to_id[i]]\n",
    "        random.shuffle(available_indices)\n",
    "        \n",
    "        n = len(available_indices)\n",
    "        # Ensure at least 1 sample in Val/Test if possible\n",
    "        n_val = max(1, int(n * val_ratio)) if n > 1 else 0\n",
    "        n_test = max(1, int(n * test_ratio)) if n > 2 else 0\n",
    "        \n",
    "        # Allocate indices\n",
    "        val_idxs = available_indices[:n_val]\n",
    "        test_idxs = available_indices[n_val:n_val+n_test]\n",
    "        train_idxs = available_indices[n_val+n_test:]\n",
    "        \n",
    "        for i in val_idxs:\n",
    "            if not sample_to_id[i]:\n",
    "                val_data.append(all_data[i])\n",
    "                sample_to_id[i] = True\n",
    "        for i in test_idxs:\n",
    "            if not sample_to_id[i]:\n",
    "                test_data.append(all_data[i])\n",
    "                sample_to_id[i] = True\n",
    "        for i in train_idxs:\n",
    "            if not sample_to_id[i]:\n",
    "                train_data.append(all_data[i])\n",
    "                sample_to_id[i] = True\n",
    "\n",
    "    # 3. Assign any leftovers\n",
    "    leftovers = [all_data[i] for i in range(len(all_data)) if not sample_to_id[i]]\n",
    "    for item in leftovers:\n",
    "        r = random.random()\n",
    "        if r < val_ratio: val_data.append(item)\n",
    "        elif r < val_ratio + test_ratio: test_data.append(item)\n",
    "        else: train_data.append(item)\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def balance_training_data(train_data, target_min_samples=30):\n",
    "    \"\"\"\n",
    "    Oversamples rare classes in the training set to reach a minimum count.\n",
    "    \"\"\"\n",
    "    print(f\"\\nBalancing training data (target min: {target_min_samples})...\")\n",
    "    class_counts = Counter()\n",
    "    class_samples = defaultdict(list)\n",
    "    \n",
    "    for item in train_data:\n",
    "        labels = get_labels_from_item(item)\n",
    "        for label in labels:\n",
    "            class_counts[label] += 1\n",
    "            class_samples[label].append(item)\n",
    "            \n",
    "    balanced_data = list(train_data)\n",
    "    added_count = 0\n",
    "    \n",
    "    for cls, count in class_counts.items():\n",
    "        if count < target_min_samples:\n",
    "            needed = target_min_samples - count\n",
    "            available = class_samples[cls]\n",
    "            if not available: continue\n",
    "            \n",
    "            # Resample with replacement\n",
    "            extras = random.choices(available, k=needed)\n",
    "            balanced_data.extend(extras)\n",
    "            added_count += needed\n",
    "\n",
    "    random.shuffle(balanced_data)\n",
    "    print(f\"  Added {added_count} samples via oversampling.\")\n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a523e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def generate_synthetic_data_pil(image, num_samples=5, use_edge_enhance=False):\n",
    "    \"\"\"\n",
    "    Creates synthetic medical images using Pillow (PIL).\n",
    "    \n",
    "    Args:\n",
    "        image (PIL.Image): Input image.\n",
    "        num_samples (int): Number of synthetic versions to create.\n",
    "        use_edge_enhance (bool): If True, applies edge enhancement (like Sobel).\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of augmented PIL images.\n",
    "    \"\"\"\n",
    "    synthetic_images = []\n",
    "    w, h = image.size\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        aug_img = image.copy()\n",
    "        \n",
    "        # --- A. GEOMETRIC TRANSFORMS ---\n",
    "        \n",
    "        # 1. Random Flip\n",
    "        if random.random() > 0.5:\n",
    "            # Mirror (Horizontal)\n",
    "            if random.random() > 0.5:\n",
    "                aug_img = ImageOps.mirror(aug_img)\n",
    "            # Flip (Vertical) - Valid for skin lesions\n",
    "            else:\n",
    "                aug_img = ImageOps.flip(aug_img)\n",
    "\n",
    "        # 2. Random Rotation (-30 to 30 degrees)\n",
    "        if random.random() > 0.5:\n",
    "            angle = random.uniform(-30, 30)\n",
    "            aug_img = aug_img.rotate(angle, resample=Image.BICUBIC, expand=False)\n",
    "\n",
    "        # 3. Random Resized Crop (Zoom effect)\n",
    "        if random.random() > 0.3:\n",
    "            scale = random.uniform(0.75, 0.95)\n",
    "            new_w, new_h = int(w * scale), int(h * scale)\n",
    "            \n",
    "            left = random.randint(0, w - new_w)\n",
    "            top = random.randint(0, h - new_h)\n",
    "            \n",
    "            aug_img = aug_img.crop((left, top, left + new_w, top + new_h))\n",
    "            aug_img = aug_img.resize((w, h), resample=Image.BICUBIC)\n",
    "\n",
    "        # --- B. PIXEL TRANSFORMS ---\n",
    "\n",
    "        # 4. Gaussian Blur\n",
    "        if random.random() > 0.7:\n",
    "            radius = random.uniform(1, 2)\n",
    "            aug_img = aug_img.filter(ImageFilter.GaussianBlur(radius))\n",
    "\n",
    "        # 5. Gaussian Noise\n",
    "        if random.random() > 0.7:\n",
    "            # Convert to numpy to add noise\n",
    "            img_arr = np.array(aug_img).astype(float)\n",
    "            noise = np.random.normal(0, 15, img_arr.shape)\n",
    "            img_arr = np.clip(img_arr + noise, 0, 255).astype('uint8')\n",
    "            aug_img = Image.fromarray(img_arr)\n",
    "\n",
    "        # 6. Color Jitter (Brightness/Contrast/Saturation)\n",
    "        if random.random() > 0.5:\n",
    "            # Brightness\n",
    "            enhancer = ImageEnhance.Brightness(aug_img)\n",
    "            aug_img = enhancer.enhance(random.uniform(0.8, 1.2))\n",
    "            \n",
    "            # Contrast\n",
    "            enhancer = ImageEnhance.Contrast(aug_img)\n",
    "            aug_img = enhancer.enhance(random.uniform(0.9, 1.1))\n",
    "            \n",
    "            # Saturation\n",
    "            enhancer = ImageEnhance.Color(aug_img)\n",
    "            aug_img = enhancer.enhance(random.uniform(0.9, 1.1))\n",
    "\n",
    "        # --- C. STRUCTURAL TRANSFORMS ---\n",
    "        \n",
    "        # 7. Edge Enhancement (Alternative to Sobel)\n",
    "        if use_edge_enhance and random.random() > 0.8:\n",
    "            # Convert to grayscale and find edges\n",
    "            gray = aug_img.convert(\"L\").filter(ImageFilter.FIND_EDGES)\n",
    "            # Convert back to RGB\n",
    "            edge_img = gray.convert(\"RGB\")\n",
    "            # Blend with original (50%)\n",
    "            aug_img = Image.blend(aug_img, edge_img, alpha=0.5)\n",
    "\n",
    "        synthetic_images.append(aug_img)\n",
    "\n",
    "    return synthetic_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "c609f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "from PIL import Image\n",
    "\n",
    "def augment_rare_classes(df, images_dir, output_dir, target_count=30):\n",
    "    \"\"\"\n",
    "    Identifies rare classes and generates synthetic images to reach target_count.\n",
    "    Skips generation if sufficient synthetic data already exists in output_dir.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Original training dataframe.\n",
    "        images_dir (str/Path): Directory containing original images.\n",
    "        output_dir (str/Path): Directory to save synthetic images and metadata.\n",
    "        target_count (int): Minimum samples desired per class.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing ALL synthetic data (previously existing + newly generated).\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Load existing synthetic metadata if it exists\n",
    "    metadata_path = output_path / \"synthetic_metadata.csv\"\n",
    "    if metadata_path.exists():\n",
    "        try:\n",
    "            existing_syn_df = pd.read_csv(metadata_path)\n",
    "            print(f\"Loaded metadata for {len(existing_syn_df)} existing synthetic samples.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not read existing metadata ({e}). Starting fresh.\")\n",
    "            existing_syn_df = pd.DataFrame()\n",
    "    else:\n",
    "        existing_syn_df = pd.DataFrame()\n",
    "\n",
    "    # Identify rare classes based on ORIGINAL data\n",
    "    counts = df['condition'].value_counts()\n",
    "    rare_classes = counts[counts < target_count].index.tolist()\n",
    "    \n",
    "    new_rows = []\n",
    "    \n",
    "    print(f\"Checking {len(rare_classes)} rare classes (Target: {target_count})...\")\n",
    "\n",
    "    for condition in rare_classes:\n",
    "        # Count original samples\n",
    "        original_count = len(df[df['condition'] == condition])\n",
    "        \n",
    "        # Count existing synthetic samples (if any)\n",
    "        if not existing_syn_df.empty:\n",
    "            syn_count = len(existing_syn_df[existing_syn_df['condition'] == condition])\n",
    "        else:\n",
    "            syn_count = 0\n",
    "            \n",
    "        # Calculate how many MORE we need\n",
    "        total_current = original_count + syn_count\n",
    "        needed = target_count - total_current\n",
    "        \n",
    "        if needed <= 0:\n",
    "            # print(f\"  ‚úì {condition}: Has {total_current} (Skipping)\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"  - {condition}: Generating {needed} new images (Original: {original_count}, Existing Syn: {syn_count})...\")\n",
    "        \n",
    "        # Get existing samples to augment\n",
    "        existing_samples = df[df['condition'] == condition]\n",
    "        if existing_samples.empty: continue\n",
    "\n",
    "        generated_count = 0\n",
    "        while generated_count < needed:\n",
    "            # Pick random source image\n",
    "            source_row = existing_samples.sample(1).iloc[0]\n",
    "            \n",
    "            img_path = Path(images_dir) / source_row['image_path']\n",
    "            try:\n",
    "                original_img = Image.open(img_path).convert(\"RGB\")\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "            # Generate synthetic version\n",
    "            # Assuming generate_synthetic_data_pil is defined as before\n",
    "            synthetic_imgs = generate_synthetic_data_pil(original_img, num_samples=1)\n",
    "            syn_img = synthetic_imgs[0]\n",
    "            \n",
    "            # --- METADATA ---\n",
    "            new_id = str(uuid.uuid4())\n",
    "            \n",
    "            # Sanitize filename\n",
    "            safe_condition_name = condition.replace(' ', '_').replace('/', '_').replace('\\\\', '_')\n",
    "            new_filename = f\"syn_{safe_condition_name}_{new_id[:8]}.png\"\n",
    "            save_path = output_path / new_filename\n",
    "            \n",
    "            # Save Image\n",
    "            syn_img.save(save_path)\n",
    "            \n",
    "            # Create Metadata Row\n",
    "            new_row = source_row.copy()\n",
    "            new_row['image_id'] = new_id\n",
    "            new_row['image_path'] = new_filename # Just filename, relative to output_dir\n",
    "            new_row['split'] = 'train'\n",
    "            \n",
    "            # Add helper flag (optional)\n",
    "            new_row['is_synthetic'] = True\n",
    "            \n",
    "            new_rows.append(new_row)\n",
    "            generated_count += 1\n",
    "\n",
    "    # 2. Combine and Save\n",
    "    if new_rows:\n",
    "        new_df = pd.DataFrame(new_rows)\n",
    "        if not existing_syn_df.empty:\n",
    "            # Align columns before concat to prevent errors\n",
    "            # (Optional safety step if schemas drift)\n",
    "            final_syn_df = pd.concat([existing_syn_df, new_df], ignore_index=True)\n",
    "        else:\n",
    "            final_syn_df = new_df\n",
    "            \n",
    "        # Save updated metadata\n",
    "        final_syn_df.to_csv(metadata_path, index=False)\n",
    "        print(f\"Saved updated metadata with {len(new_rows)} new samples to {metadata_path}\")\n",
    "        return final_syn_df\n",
    "    else:\n",
    "        print(\"No new images generated.\")\n",
    "        return existing_syn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9c1d3269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#  IMPROVED DATA LOADING SECTION (Replaces original loading logic)\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Loading and Processing Data\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Load raw CSV\n",
    "df = pd.read_csv(config.metadata_file)\n",
    "print(f\"Raw data loaded: {len(df)} samples\")\n",
    "\n",
    "# 2. Convert to list of dictionaries for processing\n",
    "all_data = df.to_dict('records')\n",
    "\n",
    "# 3. Perform Stratified Split (Fixes missing classes in Val/Test)\n",
    "train_raw, val_data, test_data = stratified_split_data(\n",
    "    all_data, \n",
    "    val_ratio=0.15, \n",
    "    test_ratio=0.15\n",
    ")\n",
    "\n",
    "# 4. Balance Training Data (Fixes class imbalance)\n",
    "# Target 30 samples ensures the model sees rare classes ~1 per batch on average\n",
    "train_balanced = balance_training_data(train_raw, target_min_samples=30)\n",
    "\n",
    "# 5. Convert back to DataFrames for compatibility\n",
    "print(f\"Training set size before adding synthetic data: {len(train_df)}\")\n",
    "train_df = pd.DataFrame(train_balanced)\n",
    "synthetic_dir = \"./scin_synthetic\"\n",
    "synthetic_df = augment_rare_classes(\n",
    "    train_df, \n",
    "    config.images_dir, \n",
    "    synthetic_dir, \n",
    "    target_count=30\n",
    ")\n",
    "\n",
    "# Merge\n",
    "train_df = pd.concat([train_df, synthetic_df], ignore_index=True)\n",
    "print(f\"New training set size after adding synthetic data: {len(train_df)}\")\n",
    "\n",
    "val_df = pd.DataFrame(val_data)\n",
    "test_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c556acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def print_comprehensive_report(df, train_df, val_df, test_df):\n",
    "    \"\"\"\n",
    "    Print a comprehensive data analysis report for SigLip fine-tuning\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\" DATASET ANALYSIS FOR SIGLIP FINE-TUNING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(\"\\n1. OVERALL DATASET STATISTICS\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Total samples: {len(df):,}\")\n",
    "    print(f\"  - Training:   {len(train_df):,} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  - Validation: {len(val_df):,} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  - Test:       {len(test_df):,} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"\\nUnique conditions: {df['condition'].nunique()}\")\n",
    "    print(f\"Unique coarse categories: {df['coarse_category'].nunique()}\")\n",
    "    \n",
    "    # Label distribution by split\n",
    "    print(\"\\n2. LABEL DISTRIBUTION BY SPLIT\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Get all unique conditions\n",
    "    all_conditions = df['condition'].unique()\n",
    "    \n",
    "    # Create distribution table\n",
    "    distribution_data = []\n",
    "    for condition in sorted(all_conditions):\n",
    "        train_count = len(train_df[train_df['condition'] == condition])\n",
    "        val_count = len(val_df[val_df['condition'] == condition])\n",
    "        test_count = len(test_df[test_df['condition'] == condition])\n",
    "        total = train_count + val_count + test_count\n",
    "        \n",
    "        distribution_data.append({\n",
    "            'Condition': condition,\n",
    "            'Train': train_count,\n",
    "            'Val': val_count,\n",
    "            'Test': test_count,\n",
    "            'Total': total\n",
    "        })\n",
    "    \n",
    "    dist_df = pd.DataFrame(distribution_data).sort_values('Total', ascending=False)\n",
    "    \n",
    "    # Print top 15 most common conditions\n",
    "    print(\"\\nTop 15 Most Common Conditions:\")\n",
    "    print(f\"{'Condition':<40} {'Train':>8} {'Val':>8} {'Test':>8} {'Total':>8}\")\n",
    "    print(\"-\" * 80)\n",
    "    for _, row in dist_df.head(15).iterrows():\n",
    "        print(f\"{row['Condition']:<40} {row['Train']:>8} {row['Val']:>8} {row['Test']:>8} {row['Total']:>8}\")\n",
    "    \n",
    "    # Print conditions with imbalanced splits (potential issues)\n",
    "    print(\"\\n3. POTENTIAL TRAINING ISSUES\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Classes with very few samples\n",
    "    rare_classes = dist_df[dist_df['Total'] < 10]\n",
    "    print(f\"\\n‚ö†Ô∏è  Conditions with <10 total samples: {len(rare_classes)}\")\n",
    "    if len(rare_classes) > 0:\n",
    "        print(\"(These may cause overfitting or poor generalization)\")\n",
    "        for _, row in rare_classes.iterrows():\n",
    "            print(f\"  - {row['Condition']:<40} (Total: {row['Total']})\")\n",
    "    \n",
    "    # Classes missing from validation or test\n",
    "    missing_val = dist_df[dist_df['Val'] == 0]\n",
    "    missing_test = dist_df[dist_df['Test'] == 0]\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  Conditions missing from validation set: {len(missing_val)}\")\n",
    "    if len(missing_val) > 0 and len(missing_val) <= 10:\n",
    "        for _, row in missing_val.iterrows():\n",
    "            print(f\"  - {row['Condition']}\")\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  Conditions missing from test set: {len(missing_test)}\")\n",
    "    if len(missing_test) > 0 and len(missing_test) <= 10:\n",
    "        for _, row in missing_test.iterrows():\n",
    "            print(f\"  - {row['Condition']}\")\n",
    "    \n",
    "    # Multi-label analysis\n",
    "    print(\"\\n4. MULTI-LABEL ANALYSIS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    def count_labels(df_subset):\n",
    "        \"\"\"Count images by number of labels\"\"\"\n",
    "        import ast\n",
    "        label_counts = []\n",
    "        for all_conds in df_subset['all_conditions']:\n",
    "            if pd.notna(all_conds):\n",
    "                try:\n",
    "                    conds = ast.literal_eval(all_conds) if isinstance(all_conds, str) else all_conds\n",
    "                    label_counts.append(len(conds))\n",
    "                except:\n",
    "                    label_counts.append(1)\n",
    "            else:\n",
    "                label_counts.append(1)\n",
    "        return Counter(label_counts)\n",
    "    \n",
    "    train_label_dist = count_labels(train_df)\n",
    "    val_label_dist = count_labels(val_df)\n",
    "    test_label_dist = count_labels(test_df)\n",
    "    \n",
    "    print(f\"{'Labels per Image':<20} {'Train':>10} {'Val':>10} {'Test':>10}\")\n",
    "    print(\"-\" * 80)\n",
    "    all_label_counts = sorted(set(list(train_label_dist.keys()) + list(val_label_dist.keys()) + list(test_label_dist.keys())))\n",
    "    for num_labels in all_label_counts:\n",
    "        print(f\"{num_labels} label(s): {train_label_dist.get(num_labels, 0):>10} {val_label_dist.get(num_labels, 0):>10} {test_label_dist.get(num_labels, 0):>10}\")\n",
    "    \n",
    "    # Calculate multi-label percentage\n",
    "    multi_label_train = sum(count for labels, count in train_label_dist.items() if labels > 1)\n",
    "    multi_label_pct = multi_label_train / len(train_df) * 100 if len(train_df) > 0 else 0\n",
    "    print(f\"\\nMulti-label samples in training: {multi_label_train:,} ({multi_label_pct:.1f}%)\")\n",
    "    \n",
    "    # Coarse category distribution\n",
    "    print(\"\\n5. COARSE CATEGORY DISTRIBUTION\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Category':<40} {'Train':>8} {'Val':>8} {'Test':>8} {'Total':>8}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for category in sorted(df['coarse_category'].unique()):\n",
    "        train_count = len(train_df[train_df['coarse_category'] == category])\n",
    "        val_count = len(val_df[val_df['coarse_category'] == category])\n",
    "        test_count = len(test_df[test_df['coarse_category'] == category])\n",
    "        total = train_count + val_count + test_count\n",
    "        print(f\"{category:<40} {train_count:>8} {val_count:>8} {test_count:>8} {total:>8}\")\n",
    "    \n",
    "    # Class imbalance metrics\n",
    "    print(\"\\n6. CLASS IMBALANCE METRICS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    train_condition_counts = train_df['condition'].value_counts()\n",
    "    max_samples = train_condition_counts.max()\n",
    "    min_samples = train_condition_counts.min()\n",
    "    imbalance_ratio = max_samples / min_samples if min_samples > 0 else float('inf')\n",
    "    \n",
    "    print(f\"Training set class imbalance:\")\n",
    "    print(f\"  - Most common class:  {train_condition_counts.index[0]:<40} ({max_samples} samples)\")\n",
    "    print(f\"  - Least common class: {train_condition_counts.index[-1]:<40} ({min_samples} samples)\")\n",
    "    print(f\"  - Imbalance ratio:    {imbalance_ratio:.1f}:1\")\n",
    "    print(f\"\\nMedian samples per class: {train_condition_counts.median():.0f}\")\n",
    "    print(f\"Mean samples per class:   {train_condition_counts.mean():.1f}\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(\"\\n7. RECOMMENDATIONS FOR SIGLIP FINE-TUNING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nüìä Data Considerations:\")\n",
    "    if imbalance_ratio > 100:\n",
    "        print(\"  ‚ö†Ô∏è  SEVERE class imbalance detected (>100:1)\")\n",
    "        print(\"     ‚Üí Consider: class weights, focal loss, or oversampling rare classes\")\n",
    "    elif imbalance_ratio > 20:\n",
    "        print(\"  ‚ö†Ô∏è  Significant class imbalance (>20:1)\")\n",
    "        print(\"     ‚Üí Consider: balanced sampling or class weights\")\n",
    "    \n",
    "    if multi_label_pct > 20:\n",
    "        print(f\"\\n  ‚ÑπÔ∏è  High multi-label percentage ({multi_label_pct:.1f}%)\")\n",
    "        print(\"     ‚Üí Use SIGMOID loss (not contrastive) for multi-label classification\")\n",
    "    else:\n",
    "        print(f\"\\n  ‚ÑπÔ∏è  Low multi-label percentage ({multi_label_pct:.1f}%)\")\n",
    "        print(\"     ‚Üí Either SIGMOID or CONTRASTIVE loss can work\")\n",
    "    \n",
    "    if len(rare_classes) > 0:\n",
    "        print(f\"\\n  ‚ö†Ô∏è  {len(rare_classes)} classes with <10 samples\")\n",
    "        print(\"     ‚Üí These may not learn well; consider grouping into coarse categories\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Call the report function\n",
    "print_comprehensive_report(df, train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0076dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for fine-grained contrastive learning with SigLIP.\n",
    "    Prioritizes verbose descriptions and robust image handling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, images_dir: Path, processor, mode='train'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.processor = processor\n",
    "        self.mode = mode\n",
    "        \n",
    "        # --- NEW: Load Synthetic Visual Descriptions ---\n",
    "        self.visual_descriptions = {}\n",
    "        try:\n",
    "            with open(config.visual_descriptions_path, 'r') as f:\n",
    "                self.visual_descriptions = json.load(f)\n",
    "            print(f\"[{mode}] Loaded {len(self.visual_descriptions)} visual descriptions.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"[{mode}] Warning: Visual descriptions file not found. Using basic labels.\")\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load Image\n",
    "        image_path = self.images_dir / row['image_path']\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except:\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "\n",
    "        # --- NEW TEXT GENERATION ---\n",
    "        condition = row['condition']\n",
    "        \n",
    "        # 1. Try to get the RICH visual description (e.g. \"Red, scaly plaques...\")\n",
    "        visual_desc = self.visual_descriptions.get(condition, \"\")\n",
    "        \n",
    "        # 2. Fallback to dataset description\n",
    "        raw_desc = str(row.get('description', ''))\n",
    "        if raw_desc.lower() == 'nan': raw_desc = \"\"\n",
    "        \n",
    "        # Construct the prompt\n",
    "        if self.mode == 'train':\n",
    "            # Training: Give the model the rich visual features\n",
    "            if visual_desc:\n",
    "                text = f\"A photo of {condition}: {visual_desc}\"\n",
    "            elif raw_desc:\n",
    "                text = f\"A photo of {condition}: {raw_desc}\"\n",
    "            else:\n",
    "                text = f\"A dermatological photo of {condition}\"\n",
    "        else:\n",
    "            # Testing: Keep it standard but descriptive\n",
    "            text = f\"A photo of {condition}: {visual_desc if visual_desc else raw_desc}\"\n",
    "\n",
    "        # Label ID for Multi-Positive Loss\n",
    "        label_id = hash(condition)\n",
    "\n",
    "        inputs = self.processor(\n",
    "            text=[text],\n",
    "            images=image,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=64,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Remove batch dimension\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].squeeze(0)\n",
    "\n",
    "        # Remove batch dimension (1, C, H, W) -> (C, H, W)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83983d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigLipModel(nn.Module):\n",
    "    \"\"\"SigLIP model for contrastive learning.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str, temperature: float = 0.07):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.temperature = temperature\n",
    "        self.logit_bias = nn.Parameter(torch.zeros(1))\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / temperature))\n",
    "\n",
    "    def forward(self, input_ids=None, pixel_values=None, attention_mask=None, **kwargs):\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            pixel_values=pixel_values,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        image_embeds = outputs.vision_model_output.pooler_output\n",
    "        text_embeds = outputs.text_model_output.pooler_output\n",
    "\n",
    "        image_embeds = F.normalize(image_embeds, dim=-1)\n",
    "        text_embeds = F.normalize(text_embeds, dim=-1)\n",
    "\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_embeds @ text_embeds.t()\n",
    "        logits_per_text = logits_per_image.t()\n",
    "\n",
    "        batch_size = image_embeds.shape[0]\n",
    "        \n",
    "        # --- Switchable Loss Calculation ---\n",
    "        if config.loss_type == \"contrastive\":\n",
    "            labels = torch.arange(batch_size, device=image_embeds.device)\n",
    "            loss_i = F.cross_entropy(logits_per_image, labels)\n",
    "            loss_t = F.cross_entropy(logits_per_text, labels)\n",
    "            loss = (loss_i + loss_t) / 2\n",
    "        elif config.loss_type == \"sigmoid\":\n",
    "            labels = torch.eye(batch_size, device=image_embeds.device)\n",
    "            loss_i = F.binary_cross_entropy_with_logits(logits_per_image, labels)\n",
    "            loss_t = F.binary_cross_entropy_with_logits(logits_per_text, labels)\n",
    "            loss = (loss_i + loss_t) / 2.0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown loss_type: {config.loss_type}\")\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits_per_image': logits_per_image,\n",
    "            'logits_per_text': logits_per_text,\n",
    "            'image_embeds': image_embeds,\n",
    "            'text_embeds': text_embeds,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "51b5d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Loading Model and Creating Datasets\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(config.model_name)\n",
    "model = SigLipModel(config.model_name, config.temperature)\n",
    "model.to(config.device)\n",
    "\n",
    "print(f\"‚úì Model loaded with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "# Create datasets\n",
    "# Note: Ensure your df has 'condition' and 'description' columns\n",
    "train_dataset = CreateDataset(train_df, config.images_dir, processor, mode='train')\n",
    "val_dataset = CreateDataset(val_df, config.images_dir, processor, mode='val')\n",
    "test_dataset = CreateDataset(test_df, config.images_dir, processor, mode='test')\n",
    "\n",
    "print(f\"‚úì Datasets created\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Val: {len(val_dataset)} samples\")\n",
    "print(f\"  Test: {len(test_dataset)} samples\")\n",
    "\n",
    "# Show sample texts\n",
    "print(\"\\nSample fine-grained texts:\")\n",
    "for i in range(3):\n",
    "    sample_text = train_df.iloc[i]['description']\n",
    "    condition = train_df.iloc[i]['condition']\n",
    "    print(f\"  [{condition}] {sample_text[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ed509424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom trainer\n",
    "class SigLipTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        # Extract labels but IGNORE them in the matrix construction\n",
    "        label_ids = inputs.pop(\"label_ids\", None) # Keep this to pop the tensor out of inputs\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        # Logits extraction (robust)\n",
    "        if isinstance(outputs, dict):\n",
    "            logits = outputs[\"logits_per_image\"]\n",
    "        else:\n",
    "            logits = outputs.logits_per_image\n",
    "            \n",
    "        batch_size = logits.shape[0]\n",
    "        device = logits.device\n",
    "        \n",
    "        # --- BIAS INCORPORATION FIX ---\n",
    "        # 1. Retrieve the logit_bias parameter safely.\n",
    "        #    We use getattr to safely handle models that might not have this parameter.\n",
    "        logit_bias = getattr(model, 'logit_bias', None)\n",
    "        \n",
    "        if logit_bias is not None:\n",
    "            # 2. Apply the bias to the logits\n",
    "            #    The bias is broadcasted across the entire [B, B] logit matrix.\n",
    "            logits = logits + logit_bias\n",
    "        # ----------------------------\n",
    "        \n",
    "        # --- CRITICAL FIX: DIAGONAL-ONLY LABELS ---\n",
    "        # We must ignore label_ids and enforce the standard SigLIP diagonal.\n",
    "        # This stops the conflicting gradients (Image A vs Image B of same class).\n",
    "        labels = torch.eye(batch_size, device=device, dtype=logits.dtype)\n",
    "        \n",
    "        # --- POSITIVE WEIGHT CALCULATION ---\n",
    "        # The weight remains, forcing the model to value the diagonal pair highly.\n",
    "        pos_weight_value = float(batch_size - 1) if batch_size > 1 else 1.0\n",
    "        pos_weight = torch.tensor([pos_weight_value], device=device, dtype=logits.dtype)\n",
    "        \n",
    "        # --- WEIGHTED SIGMOID LOSS ---\n",
    "        # This is now standard SigLIP loss, but with heavy positive weighting.\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            logits, \n",
    "            labels, \n",
    "            pos_weight=pos_weight\n",
    "        )\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        \"\"\"Custom prediction step for contrastive learning.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs['loss']\n",
    "\n",
    "        if prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "\n",
    "        return (loss, outputs['logits_per_image'].cpu(), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f67baf2",
   "metadata": {},
   "source": [
    "## 1. Loss Analysis Diagnosis Table\n",
    "\n",
    "| Training Loss | Validation Loss | Diagnosis | Action Required |\n",
    "|---------------|-----------------|-----------|-----------------|\n",
    "| High | High | **Underfitting** | Increase model complexity, train longer |\n",
    "| Low | High (Increasing) | **Overfitting** | Add regularization (Dropout/L2), get more data, Early Stopping |\n",
    "| Low | Low | **Good Fit** | Save model weights |\n",
    "| High | Low | **Data Issue** | Check regularization, data augmentation, or data split |\n",
    "\n",
    "## 2. Loss Value Interpretation Table\n",
    "\n",
    "| Value Range | Meaning | Status |\n",
    "|-------------|---------|--------|\n",
    "| > 0.60 | **High** | Underfitting / Starting: Model is guessing |\n",
    "| 0.40 - 0.60 | **Medium** | Learning: Model is picking up patterns |\n",
    "| < 0.30 | **Low** | Good Fit: Model is confident in its predictions |\n",
    "\n",
    "## 3. Additional Metrics for Multi-Label Classification\n",
    "\n",
    "| Metric | Good Range | Interpretation |\n",
    "|--------|------------|----------------|\n",
    "| **Per-class Accuracy** | > 0.70 | Percentage of correct predictions per condition |\n",
    "| **Macro F1-Score** | > 0.60 | Average F1 across all classes (handles imbalance) |\n",
    "| **Hamming Loss** | < 0.20 | Fraction of wrong labels (lower is better) |\n",
    "| **Subset Accuracy** | > 0.40 | Exact match of all labels (strict metric) |\n",
    "\n",
    "## 4. SigLip Fine-tuning Specific Guidelines\n",
    "\n",
    "| Training Stage | Expected Train Loss | Expected Val Loss | What to Look For |\n",
    "|----------------|-------------------|-------------------|------------------|\n",
    "| **Early (Epoch 1-3)** | 0.80 - 1.20 | 0.70 - 1.10 | Both should decrease rapidly |\n",
    "| **Mid (Epoch 4-8)** | 0.40 - 0.70 | 0.45 - 0.75 | Val loss should track train loss closely |\n",
    "| **Late (Epoch 9-15)** | 0.20 - 0.45 | 0.30 - 0.55 | Gap should be small (<0.10) |\n",
    "| **Converged** | < 0.30 | < 0.40 | Both stable, gap <0.10 means good generalization |\n",
    "\n",
    "## 5. Warning Signs During Training\n",
    "\n",
    "| Observation | Problem | Solution |\n",
    "|-------------|---------|----------|\n",
    "| Val loss increases after epoch 5 | **Overfitting** | Enable early stopping, increase dropout |\n",
    "| Both losses stuck > 0.70 | **Underfitting** | Decrease LoRA rank, increase learning rate |\n",
    "| Val loss oscillates wildly | **Unstable training** | Reduce learning rate, increase batch size |\n",
    "| Train loss = 0.0, Val loss > 1.0 | **Severe overfitting** | Add strong regularization, reduce model capacity |\n",
    "| Gap between train/val > 0.20 | **Poor generalization** | More data augmentation, check data leakage |\n",
    "\n",
    "## 6. Recommended Actions Based on Your Dataset\n",
    "\n",
    "Given your characteristics:\n",
    "- **79.4% multi-label samples** ‚Üí Focus on Hamming Loss and Macro F1\n",
    "- **758:1 class imbalance** ‚Üí Monitor per-class metrics, not just overall accuracy\n",
    "- **9 rare classes (<10 samples)** ‚Üí These will have high loss; group to coarse categories\n",
    "\n",
    "| Target Metrics (Epoch 15) | Realistic Goal | Stretch Goal |\n",
    "|---------------------------|----------------|--------------|\n",
    "| **Validation Loss** | < 0.40 | < 0.30 |\n",
    "| **Macro F1-Score** | > 0.55 | > 0.65 |\n",
    "| **Top-3 Accuracy** | > 0.80 | > 0.90 |\n",
    "| **Hamming Loss** | < 0.25 | < 0.15 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2f468d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 26:38, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.335400</td>\n",
       "      <td>0.741521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.334100</td>\n",
       "      <td>0.734111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.329100</td>\n",
       "      <td>0.726259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.326200</td>\n",
       "      <td>0.719635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.321700</td>\n",
       "      <td>0.714725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.317700</td>\n",
       "      <td>0.711181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.312100</td>\n",
       "      <td>0.709177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.307700</td>\n",
       "      <td>0.707673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.301400</td>\n",
       "      <td>0.706846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.297400</td>\n",
       "      <td>0.706235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.294200</td>\n",
       "      <td>0.705937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.291400</td>\n",
       "      <td>0.705707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.290400</td>\n",
       "      <td>0.705645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.286400</td>\n",
       "      <td>0.705652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.286000</td>\n",
       "      <td>0.705646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # predictions (logits) are tuple: (logits_per_image, logits_per_text)\n",
    "    logits = eval_pred.predictions \n",
    "    # Robustly handle tuple unpacking\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "    \n",
    "    # For evaluation, we treat the diagonal as the ground truth class\n",
    "    # (retrieval task: given image i, find text i)\n",
    "    batch_size = logits.shape[0]\n",
    "    labels = np.arange(batch_size)\n",
    "    \n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(config.output_dir),\n",
    "    num_train_epochs=config.num_epochs,\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    per_device_eval_batch_size=config.batch_size,\n",
    "    learning_rate=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    "    warmup_steps=config.warmup_steps,\n",
    "    fp16=config.fp16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2, #Was 3\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_num_workers=0,\n",
    "    report_to=\"none\",\n",
    "    prediction_loss_only=False, # CRITICAL for compute_metrics to run!\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "lora_config = LoraConfig(\n",
    "        r=config.lora_alpha,\n",
    "        lora_alpha=config.lora_alpha,\n",
    "        target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\", \"fc1\", \"fc2\"],\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "    )\n",
    "\n",
    "# Apply LoRA if specified\n",
    "if config.finetune_mode == \"LoRA\":\n",
    "    print(\"\\nApplying LoRA fine-tuning...\")\n",
    "    model = get_peft_model(model, lora_config)  \n",
    "\n",
    "# 1. Create the callback instance\n",
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=5)\n",
    "\n",
    "trainer = SigLipTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING FINE-GRAINED TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(\"Training with fine-grained condition labels...\")\n",
    "print(\"Focus on discriminating between 66 specific conditions\")\n",
    "print()\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(f\"\\n‚úì Training complete! Final loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(f\"‚úì Test loss: {test_results['eval_loss']:.4f}\")\n",
    "\n",
    "# Save\n",
    "final_path = config.output_dir / 'final_model'\n",
    "trainer.save_model(str(final_path))\n",
    "processor.save_pretrained(str(final_path))\n",
    "print(f\"‚úì Model saved to: {final_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "67d565dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_retrieval(model, processor, test_df, images_dir, n_samples=20, debug_limit=5):\n",
    "    \"\"\"\n",
    "    Test fine-grained retrieval capabilities with detailed debugging.\n",
    "    \n",
    "    Args:\n",
    "        debug_limit (int): Number of samples to print detailed logs for.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Ensure we don't sample more than available\n",
    "    n_samples = min(n_samples, len(test_df))\n",
    "    sample_indices = np.random.choice(len(test_df), n_samples, replace=False)\n",
    "\n",
    "    accuracies = []\n",
    "    condition_accuracies = {}\n",
    "    debug_counter = 0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"New Testing retrieval on {n_samples} samples...\")\n",
    "    print(f\"Detailed debug info will be printed for the first {debug_limit} samples.\\n\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    for idx in tqdm(sample_indices, desc=\"Testing retrieval\"):\n",
    "        row = test_df.iloc[idx]\n",
    "\n",
    "        # 1. Load Image\n",
    "        image_path = images_dir / row['image_path']\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        # 2. Prepare Candidates\n",
    "        desc = str(row['description'])\n",
    "        if desc.lower() == 'nan' or not desc:\n",
    "            correct_text = f\"A dermatological image of {row['condition']}\"\n",
    "        else:\n",
    "            correct_text = f\"A dermatological image of {row['condition']}: {desc}\"\n",
    "            \n",
    "        correct_condition = row['condition']\n",
    "\n",
    "        # Get distractors\n",
    "        other_conditions = test_df[test_df['condition'] != correct_condition]['condition'].unique()\n",
    "        \n",
    "        n_distractors = min(9, len(other_conditions))\n",
    "        if n_distractors < 1: continue\n",
    "\n",
    "        distractor_conditions = np.random.choice(other_conditions, n_distractors, replace=False)\n",
    "\n",
    "        distractor_texts = []\n",
    "        for dist_cond in distractor_conditions:\n",
    "            dist_rows = test_df[test_df['condition'] == dist_cond]\n",
    "            if len(dist_rows) > 0:\n",
    "                dist_row = dist_rows.sample(1).iloc[0]\n",
    "                # Clean description logic for distractors too\n",
    "                d_desc = str(dist_row['description'])\n",
    "                if d_desc.lower() == 'nan' or not d_desc:\n",
    "                     d_text = f\"A dermatological image of {dist_row['condition']}\"\n",
    "                else:\n",
    "                     d_text = f\"A dermatological image of {dist_row['condition']}: {d_desc}\"\n",
    "                distractor_texts.append(d_text)\n",
    "\n",
    "        # Index 0 is ALWAYS the correct answer in this list\n",
    "        all_texts = [correct_text] + distractor_texts\n",
    "\n",
    "        # 3. Process Inputs\n",
    "        inputs = processor(\n",
    "            text=all_texts,\n",
    "            images=[image] * len(all_texts),\n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=64, \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(config.device)\n",
    "\n",
    "        # 4. Get Predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "            if isinstance(outputs, dict):\n",
    "                logits_per_image = outputs['logits_per_image']\n",
    "            else:\n",
    "                logits_per_image = outputs.logits_per_image\n",
    "            \n",
    "            # Get logits for the single image against all texts\n",
    "            logits = logits_per_image[0]\n",
    "            \n",
    "            # Apply Sigmoid to get readable probabilities (0.0 to 1.0)\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "        # 5. Check accuracy\n",
    "        predicted_idx = probs.argmax().item()\n",
    "        correct = (predicted_idx == 0)\n",
    "        accuracies.append(correct)\n",
    "\n",
    "        # Track per-condition accuracy\n",
    "        if correct_condition not in condition_accuracies:\n",
    "            condition_accuracies[correct_condition] = []\n",
    "        condition_accuracies[correct_condition].append(correct)\n",
    "\n",
    "        # --- DEBUGGING OUTPUT ---\n",
    "        if debug_counter < debug_limit:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"DEBUG SAMPLE {debug_counter + 1} | Condition: {correct_condition}\")\n",
    "            print(f\"Image Path: {image_path}\")\n",
    "            print(f\"Result: {'‚úÖ CORRECT' if correct else '‚ùå INCORRECT'}\")\n",
    "            print(f\"{'-'*40}\")\n",
    "            \n",
    "            # Get Top 5 predictions for this image\n",
    "            top_k = min(5, len(all_texts))\n",
    "            top_probs, top_indices = torch.topk(probs, top_k)\n",
    "            \n",
    "            print(f\"Model's Top {top_k} Guesses:\")\n",
    "            for score, idx in zip(top_probs, top_indices):\n",
    "                idx = idx.item()\n",
    "                score = score.item()\n",
    "                \n",
    "                is_ground_truth = (idx == 0)\n",
    "                marker = \"üëà TRUE LABEL\" if is_ground_truth else \"\"\n",
    "                \n",
    "                # Truncate text for cleaner printing\n",
    "                display_text = all_texts[idx][:100] + \"...\" if len(all_texts[idx]) > 100 else all_texts[idx]\n",
    "                \n",
    "                print(f\"  [{score:.4f}] {display_text} {marker}\")\n",
    "\n",
    "            # If correct answer wasn't in top 5, print it explicitly\n",
    "            if 0 not in top_indices.tolist():\n",
    "                true_score = probs[0].item()\n",
    "                print(f\"  ...\\n  [{true_score:.4f}] {correct_text} üëà TRUE LABEL (Ranked > {top_k})\")\n",
    "                \n",
    "            print(f\"{'='*80}\\n\")\n",
    "            debug_counter += 1\n",
    "\n",
    "    if not accuracies:\n",
    "        return 0.0\n",
    "\n",
    "    accuracy = np.mean(accuracies)\n",
    "    print(f\"\\n‚úì Fine-grained retrieval accuracy: {accuracy:.2%}\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "bb22c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing retrieval: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:01<00:00, 10.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Test retrieval\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Testing Fine-Grained Retrieval\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "retrieval_acc = test_retrieval(model, processor, test_df, config.images_dir)\n",
    "\n",
    "# Save summary\n",
    "summary = {\n",
    "    'approach': 'fine_grained',\n",
    "    'num_conditions': int(df['condition'].nunique()),\n",
    "    'train_samples': len(train_df),\n",
    "    'final_loss': float(train_result.training_loss),\n",
    "    'test_loss': float(test_results['eval_loss']),\n",
    "    'retrieval_accuracy': float(retrieval_acc),\n",
    "}\n",
    "\n",
    "with open(config.output_dir / 'training_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINE-GRAINED TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAdvantages of fine-grained approach:\")\n",
    "print(\"  ‚Ä¢ Direct discrimination between 66 specific conditions\")\n",
    "print(\"  ‚Ä¢ No hierarchical complexity\")\n",
    "print(\"  ‚Ä¢ Focused on exact condition matching\")\n",
    "print(\"  ‚Ä¢ Should improve retrieval accuracy\")\n",
    "print(f\"\\nFinal metrics:\")\n",
    "print(f\"  Test loss: {test_results['eval_loss']:.4f}\")\n",
    "print(f\"  Retrieval accuracy: {retrieval_acc:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health-kiosk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
