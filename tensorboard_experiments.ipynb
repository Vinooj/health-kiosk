{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a26a2b",
   "metadata": {},
   "source": [
    "### **TensorBoard Integration with HuggingFace Trainer**\n",
    "---\n",
    "A comprehensive guide to leveraging TensorBoard features with HuggingFace models\n",
    "\n",
    "Features covered:\n",
    "1. Scalars (loss, metrics, learning rate)\n",
    "2. Images (input samples, attention maps)\n",
    "3. Embeddings (high-dimensional visualization)\n",
    "4. Graphs (model architecture)\n",
    "5. Histograms (weight distributions)\n",
    "6. Hyperparameters (HP tuning comparison)\n",
    "7. Confusion Matrix\n",
    "8. PR Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e17f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INSTALLATION & IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "# !pip install transformers datasets tensorboard torch torchvision evaluate scikit-learn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. SETUP: MODEL, DATASET & TOKENIZER\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading model and dataset...\")\n",
    "\n",
    "# Using IMDB for sentiment analysis (binary classification)\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "DATASET_NAME = \"imdb\"\n",
    "NUM_LABELS = 2\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(DATASET_NAME, split={'train': 'train[:1000]', 'test': 'test[:200]'})\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=NUM_LABELS,\n",
    "    output_attentions=True,  # Important for attention visualization\n",
    "    output_hidden_states=True  # Important for embeddings\n",
    ")\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aa50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. CUSTOM TENSORBOARD CALLBACK\n",
    "# ============================================================================\n",
    "\n",
    "class AdvancedTensorBoardCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Enhanced TensorBoard callback for comprehensive logging\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_dir=\"./runs\"):\n",
    "        self.log_dir = log_dir\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "        self.step = 0\n",
    "        self.predictions_cache = []\n",
    "        self.labels_cache = []\n",
    "        \n",
    "    def on_train_begin(self, args, state, control, model=None, **kwargs):\n",
    "        \"\"\"Log model graph and hyperparameters\"\"\"\n",
    "        \n",
    "        # 1. LOG MODEL GRAPH\n",
    "        print(\"Logging model graph...\")\n",
    "        dummy_input = torch.randint(0, 1000, (1, MAX_LENGTH)).to(model.device)\n",
    "        dummy_attention = torch.ones((1, MAX_LENGTH)).to(model.device)\n",
    "        \n",
    "        try:\n",
    "            self.writer.add_graph(\n",
    "                model, \n",
    "                (dummy_input, dummy_attention)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Could not log graph: {e}\")\n",
    "        \n",
    "        # 2. LOG HYPERPARAMETERS\n",
    "        hparams = {\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'batch_size': args.per_device_train_batch_size,\n",
    "            'epochs': args.num_train_epochs,\n",
    "            'weight_decay': args.weight_decay,\n",
    "            'warmup_steps': args.warmup_steps,\n",
    "            'model_name': MODEL_NAME,\n",
    "        }\n",
    "        \n",
    "        # Log as text\n",
    "        hparam_text = json.dumps(hparams, indent=2)\n",
    "        self.writer.add_text('Hyperparameters', hparam_text, 0)\n",
    "        \n",
    "        print(\"Training setup logged to TensorBoard\")\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        \"\"\"Log scalars during training\"\"\"\n",
    "        if logs is not None:\n",
    "            for key, value in logs.items():\n",
    "                if isinstance(value, (int, float)):\n",
    "                    self.writer.add_scalar(f'train/{key}', value, state.global_step)\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, model=None, **kwargs):\n",
    "        \"\"\"Log weight histograms and distributions at epoch end\"\"\"\n",
    "        \n",
    "        print(f\"Logging weight distributions for epoch {state.epoch}...\")\n",
    "        \n",
    "        # LOG WEIGHT HISTOGRAMS\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                # Weight values\n",
    "                self.writer.add_histogram(\n",
    "                    f'weights/{name}', \n",
    "                    param.data.cpu().numpy(), \n",
    "                    state.global_step\n",
    "                )\n",
    "                # Gradient values\n",
    "                self.writer.add_histogram(\n",
    "                    f'gradients/{name}', \n",
    "                    param.grad.cpu().numpy(), \n",
    "                    state.global_step\n",
    "                )\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        \"\"\"Log evaluation metrics\"\"\"\n",
    "        if metrics is not None:\n",
    "            for key, value in metrics.items():\n",
    "                if isinstance(value, (int, float)):\n",
    "                    self.writer.add_scalar(f'eval/{key}', value, state.global_step)\n",
    "    \n",
    "    def on_train_end(self, args, state, control, model=None, **kwargs):\n",
    "        \"\"\"Generate final visualizations\"\"\"\n",
    "        print(\"Training complete. Generating final visualizations...\")\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838cb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. CUSTOM CALLBACK FOR ADVANCED VISUALIZATIONS\n",
    "# ============================================================================\n",
    "\n",
    "class VisualizationCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Callback for advanced visualizations: attention maps, embeddings, confusion matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, eval_dataset, tokenizer, log_dir=\"./runs\"):\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "        self.all_predictions = []\n",
    "        self.all_labels = []\n",
    "        \n",
    "    def on_evaluate(self, args, state, control, model=None, **kwargs):\n",
    "        \"\"\"Generate visualizations during evaluation\"\"\"\n",
    "        \n",
    "        if state.global_step % 100 == 0:  # Log every 100 steps\n",
    "            self._log_attention_maps(model, state.global_step)\n",
    "            self._log_sample_predictions(model, state.global_step)\n",
    "    \n",
    "    def _log_attention_maps(self, model, step):\n",
    "        \"\"\"Visualize attention weights\"\"\"\n",
    "        \n",
    "        print(f\"Logging attention maps at step {step}...\")\n",
    "        \n",
    "        model.eval()\n",
    "        # Get a sample\n",
    "        sample_idx = np.random.randint(0, len(self.eval_dataset))\n",
    "        sample = self.eval_dataset[sample_idx]\n",
    "        \n",
    "        input_ids = torch.tensor([sample['input_ids']]).to(model.device)\n",
    "        attention_mask = torch.tensor([sample['attention_mask']]).to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, output_attentions=True)\n",
    "            attentions = outputs.attentions  # Tuple of attention weights per layer\n",
    "        \n",
    "        # Visualize last layer attention (head 0)\n",
    "        last_layer_attention = attentions[-1][0, 0].cpu().numpy()  # [seq_len, seq_len]\n",
    "        \n",
    "        # Create heatmap\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        sns.heatmap(last_layer_attention[:50, :50], cmap='viridis', ax=ax, cbar=True)\n",
    "        ax.set_title('Attention Weights (Last Layer, Head 0)')\n",
    "        ax.set_xlabel('Key Position')\n",
    "        ax.set_ylabel('Query Position')\n",
    "        \n",
    "        # Log to tensorboard\n",
    "        self.writer.add_figure('attention/last_layer_head_0', fig, step)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def _log_sample_predictions(self, model, step):\n",
    "        \"\"\"Log sample text predictions as images\"\"\"\n",
    "        \n",
    "        print(f\"Logging sample predictions at step {step}...\")\n",
    "        \n",
    "        model.eval()\n",
    "        samples = []\n",
    "        \n",
    "        for i in range(min(5, len(self.eval_dataset))):\n",
    "            sample = self.eval_dataset[i]\n",
    "            input_ids = torch.tensor([sample['input_ids']]).to(model.device)\n",
    "            attention_mask = torch.tensor([sample['attention_mask']]).to(model.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "            \n",
    "            # Decode text\n",
    "            text = self.tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "            text = text[:100] + \"...\" if len(text) > 100 else text\n",
    "            \n",
    "            label_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "            samples.append({\n",
    "                'text': text,\n",
    "                'true': label_map[sample['label']],\n",
    "                'pred': label_map[prediction],\n",
    "                'correct': prediction == sample['label']\n",
    "            })\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(5, 1, figsize=(12, 10))\n",
    "        fig.suptitle('Sample Predictions', fontsize=16)\n",
    "        \n",
    "        for i, (ax, sample) in enumerate(zip(axes, samples)):\n",
    "            ax.axis('off')\n",
    "            color = 'green' if sample['correct'] else 'red'\n",
    "            text_content = f\"Text: {sample['text']}\\nTrue: {sample['true']} | Pred: {sample['pred']}\"\n",
    "            ax.text(0.05, 0.5, text_content, fontsize=10, verticalalignment='center',\n",
    "                   bbox=dict(boxstyle='round', facecolor=color, alpha=0.3))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        self.writer.add_figure('predictions/samples', fig, step)\n",
    "        plt.close(fig)\n",
    "    \n",
    "    def on_prediction_step(self, args, state, control, **kwargs):\n",
    "        \"\"\"Cache predictions for confusion matrix\"\"\"\n",
    "        # This would be called during evaluation\n",
    "        pass\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, model=None, metrics=None, **kwargs):\n",
    "        \"\"\"Generate confusion matrix after evaluation\"\"\"\n",
    "        \n",
    "        # Run evaluation to get predictions\n",
    "        if model is not None:\n",
    "            self._generate_confusion_matrix(model, state.global_step)\n",
    "    \n",
    "    def _generate_confusion_matrix(self, model, step):\n",
    "        \"\"\"Generate and log confusion matrix\"\"\"\n",
    "        \n",
    "        print(f\"Generating confusion matrix at step {step}...\")\n",
    "        \n",
    "        model.eval()\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Get predictions for eval set\n",
    "        for i in range(len(self.eval_dataset)):\n",
    "            sample = self.eval_dataset[i]\n",
    "            input_ids = torch.tensor([sample['input_ids']]).to(model.device)\n",
    "            attention_mask = torch.tensor([sample['attention_mask']]).to(model.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "            \n",
    "            all_predictions.append(prediction)\n",
    "            all_labels.append(sample['label'])\n",
    "        \n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(all_labels, all_predictions)\n",
    "        \n",
    "        # Visualize\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                   xticklabels=['Negative', 'Positive'],\n",
    "                   yticklabels=['Negative', 'Positive'])\n",
    "        ax.set_title('Confusion Matrix')\n",
    "        ax.set_ylabel('True Label')\n",
    "        ax.set_xlabel('Predicted Label')\n",
    "        \n",
    "        self.writer.add_figure('evaluation/confusion_matrix', fig, step)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        # Log classification report as text\n",
    "        report = classification_report(all_labels, all_predictions, \n",
    "                                      target_names=['Negative', 'Positive'])\n",
    "        self.writer.add_text('evaluation/classification_report', f\"```\\n{report}\\n```\", step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. EMBEDDING VISUALIZATION CALLBACK\n",
    "# ============================================================================\n",
    "\n",
    "class EmbeddingCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Log embeddings for visualization in TensorBoard's projector\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, eval_dataset, tokenizer, log_dir=\"./runs\"):\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, model=None, **kwargs):\n",
    "        \"\"\"Extract and log embeddings\"\"\"\n",
    "        \n",
    "        if state.global_step % 200 == 0:  # Log less frequently\n",
    "            print(f\"Logging embeddings at step {state.global_step}...\")\n",
    "            \n",
    "            model.eval()\n",
    "            embeddings_list = []\n",
    "            labels_list = []\n",
    "            metadata_list = []\n",
    "            \n",
    "            # Extract embeddings for subset of data\n",
    "            num_samples = min(100, len(self.eval_dataset))\n",
    "            \n",
    "            for i in range(num_samples):\n",
    "                sample = self.eval_dataset[i]\n",
    "                input_ids = torch.tensor([sample['input_ids']]).to(model.device)\n",
    "                attention_mask = torch.tensor([sample['attention_mask']]).to(model.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids, attention_mask=attention_mask, \n",
    "                                   output_hidden_states=True)\n",
    "                    # Use [CLS] token embedding from last hidden state\n",
    "                    embedding = outputs.hidden_states[-1][0, 0, :].cpu().numpy()\n",
    "                \n",
    "                embeddings_list.append(embedding)\n",
    "                labels_list.append(sample['label'])\n",
    "                \n",
    "                # Create metadata (first 50 chars of text)\n",
    "                text = self.tokenizer.decode(sample['input_ids'], skip_special_tokens=True)\n",
    "                metadata_list.append(text[:50])\n",
    "            \n",
    "            # Stack embeddings\n",
    "            embeddings_tensor = torch.tensor(np.array(embeddings_list))\n",
    "            \n",
    "            # Log to tensorboard\n",
    "            self.writer.add_embedding(\n",
    "                embeddings_tensor,\n",
    "                metadata=metadata_list,\n",
    "                label_img=None,\n",
    "                global_step=state.global_step,\n",
    "                tag='sentence_embeddings'\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. TRAINING CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Create log directory with timestamp\n",
    "log_dir = f\"./runs/hf_tensorboard_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=100,\n",
    "    logging_dir=log_dir,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"tensorboard\",  # Enable TensorBoard\n",
    ")\n",
    "\n",
    "# Compute metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 6. INITIALIZE TRAINER WITH CALLBACKS\n",
    "# ============================================================================\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        AdvancedTensorBoardCallback(log_dir=log_dir),\n",
    "        VisualizationCallback(\n",
    "            tokenized_datasets[\"test\"], \n",
    "            tokenizer, \n",
    "            log_dir=log_dir\n",
    "        ),\n",
    "        EmbeddingCallback(\n",
    "            tokenized_datasets[\"test\"],\n",
    "            tokenizer,\n",
    "            log_dir=log_dir\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3ce61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 7. TRAIN THE MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Starting training with TensorBoard logging...\")\n",
    "print(f\"TensorBoard logs will be saved to: {log_dir}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d49dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 8. FINAL EVALUATION & VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Running final evaluation...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"\\nFinal Evaluation Results:\")\n",
    "print(json.dumps(eval_results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 9. LAUNCH TENSORBOARD\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Training complete!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTo view TensorBoard, run:\")\n",
    "print(f\"  tensorboard --logdir {log_dir}\")\n",
    "print(\"\\nThen open: http://localhost:6006\")\n",
    "print(\"\\nFeatures available in TensorBoard:\")\n",
    "print(\"  • SCALARS: Loss, accuracy, learning rate curves\")\n",
    "print(\"  • IMAGES: Attention heatmaps, sample predictions\")\n",
    "print(\"  • GRAPHS: Model architecture\")\n",
    "print(\"  • DISTRIBUTIONS: Weight and gradient distributions\")\n",
    "print(\"  • HISTOGRAMS: Weight changes over time\")\n",
    "print(\"  • PROJECTOR: Embedding visualization (PCA/t-SNE)\")\n",
    "print(\"  • TEXT: Hyperparameters, classification reports\")\n",
    "print(\"  • HPARAMS: Hyperparameter comparison (run multiple experiments)\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323383cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: Launch TensorBoard programmatically (uncomment to use)\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir {log_dir}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
