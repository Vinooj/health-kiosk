{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d3576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinoo/projects/health-kiosk/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SIGLIP FINE-GRAINED CONTRASTIVE LEARNING\n",
      "================================================================================\n",
      "Using 66 fine-grained condition labels for precise matching\n",
      "Direct condition-level contrastive learning\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Model: google/siglip-base-patch16-224\n",
      "  Output: siglip_fine_grained\n",
      "  Device: cuda\n",
      "  Batch size: 32\n",
      "  Epochs: 25\n",
      "\n",
      "================================================================================\n",
      "Loading Data\n",
      "================================================================================\n",
      "Total samples: 5909\n",
      "Fine-grained conditions: 66\n",
      "Coarse categories: 16\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Train SigLIP with FINE-GRAINED contrastive learning.\n",
    "Uses the 66 specific condition labels with their descriptions for more precise matching.\n",
    "\n",
    "This approach should provide:\n",
    "- Better discrimination between specific conditions\n",
    "- More precise retrieval accuracy\n",
    "- Direct condition-level matching without hierarchical complexity\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SIGLIP FINE-GRAINED CONTRASTIVE LEARNING\")\n",
    "print(\"=\"*80)\n",
    "print(\"Using 66 fine-grained condition labels for precise matching\")\n",
    "print(\"Direct condition-level contrastive learning\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Data paths\n",
    "    data_dir: Path = Path('/home/agentic-health/data')\n",
    "    metadata_file: Path = './data/coarse_labeled_metadata_with_labels.csv'\n",
    "    images_dir: Path = data_dir / 'scin/images'\n",
    "\n",
    "    # Model\n",
    "    model_name: str = 'google/siglip-base-patch16-224'\n",
    "    output_dir: Path = Path('./siglip_fine_grained')\n",
    "\n",
    "    # Training\n",
    "    batch_size: int = 32\n",
    "    num_epochs: int = 25\n",
    "    learning_rate: float = 1e-5\n",
    "    weight_decay: float = 1e-4\n",
    "    warmup_steps: int = 500\n",
    "\n",
    "    # Device\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    fp16: bool = torch.cuda.is_available()\n",
    "    temperature: float = 0.07\n",
    "\n",
    "config = Config()\n",
    "config.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Model: {config.model_name}\")\n",
    "print(f\"  Output: {config.output_dir}\")\n",
    "print(f\"  Device: {config.device}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "print(f\"  Epochs: {config.num_epochs}\")\n",
    "\n",
    "# Load data\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Loading Data\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = pd.read_csv(config.metadata_file)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Fine-grained conditions: {df['condition'].nunique()}\")\n",
    "print(f\"Coarse categories: {df['coarse_category'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9177135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most common conditions:\n",
      "  Eczema                             : 1079 (18.3%)\n",
      "  Allergic Contact Dermatitis        :  590 (10.0%)\n",
      "  Urticaria                          :  442 ( 7.5%)\n",
      "  Insect Bite                        :  401 ( 6.8%)\n",
      "  Folliculitis                       :  306 ( 5.2%)\n",
      "  Psoriasis                          :  234 ( 4.0%)\n",
      "  Tinea                              :  211 ( 3.6%)\n",
      "  Impetigo                           :  136 ( 2.3%)\n",
      "  Herpes Zoster                      :  130 ( 2.2%)\n",
      "  Drug Rash                          :  129 ( 2.2%)\n",
      "\n",
      "10 rarest conditions:\n",
      "  Infected eczema                    :   12 ( 0.2%)\n",
      "  Skin infection                     :    9 ( 0.2%)\n",
      "  Melasma                            :    9 ( 0.2%)\n",
      "  Bullous Pemphigoid                 :    6 ( 0.1%)\n",
      "  Vitiligo                           :    4 ( 0.1%)\n",
      "  Kaposi's sarcoma of skin           :    4 ( 0.1%)\n",
      "  Melanoma                           :    3 ( 0.1%)\n",
      "  Pityriasis rubra pilaris           :    2 ( 0.0%)\n",
      "  Petechiae                          :    2 ( 0.0%)\n",
      "  Hyperpigmentation                  :    1 ( 0.0%)\n",
      "\n",
      "Splits: Train=4136, Val=886, Test=887\n"
     ]
    }
   ],
   "source": [
    "# Show condition distribution\n",
    "print(\"\\nTop 10 most common conditions:\")\n",
    "condition_counts = df['condition'].value_counts()\n",
    "for condition, count in condition_counts.head(10).items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"  {condition:35s}: {count:4d} ({pct:4.1f}%)\")\n",
    "\n",
    "print(\"\\n10 rarest conditions:\")\n",
    "for condition, count in condition_counts.tail(10).items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"  {condition:35s}: {count:4d} ({pct:4.1f}%)\")\n",
    "\n",
    "# Split data\n",
    "train_df = df[df['split'] == 'train'].reset_index(drop=True)\n",
    "val_df = df[df['split'] == 'val'].reset_index(drop=True)\n",
    "test_df = df[df['split'] == 'test'].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nSplits: Train={len(train_df)}, Val={len(val_df)}, Test={len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0076dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FineGrainedContrastiveDataset(Dataset):\n",
    "    \"\"\"Dataset for fine-grained contrastive learning.\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, images_dir: Path, processor, mode='train'):\n",
    "        self.df = df\n",
    "        self.images_dir = images_dir\n",
    "        self.processor = processor\n",
    "        self.mode = mode\n",
    "\n",
    "        # Templates focusing on specific conditions\n",
    "        self.templates = {\n",
    "            'condition_focused': [\n",
    "                \"{condition}\",\n",
    "                \"Patient with {condition}\",\n",
    "                \"Clinical image of {condition}\",\n",
    "                \"Diagnosed as {condition}\",\n",
    "                \"{condition}: {description}\",\n",
    "            ],\n",
    "            'detailed': [\n",
    "                \"{condition} - {description}\",\n",
    "                \"Medical condition: {condition}. {description}\",\n",
    "                \"{description} (Diagnosis: {condition})\",\n",
    "            ],\n",
    "            'category_hint': [\n",
    "                \"{condition} ({coarse})\",\n",
    "                \"{condition}, a type of {coarse}\",\n",
    "                \"{coarse} condition: {condition}\",\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def create_fine_grained_text(self, row):\n",
    "        \"\"\"Create text focusing on fine-grained condition.\"\"\"\n",
    "        condition = row['condition'].lower()\n",
    "        description = row['description']\n",
    "        coarse = row['coarse_category'].lower()\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            # Varied templates for training\n",
    "            template_type = np.random.choice(list(self.templates.keys()), p=[0.4, 0.4, 0.2])\n",
    "            template = np.random.choice(self.templates[template_type])\n",
    "\n",
    "            text = template.format(\n",
    "                condition=condition,\n",
    "                description=description,\n",
    "                coarse=coarse\n",
    "            )\n",
    "\n",
    "            # Sometimes add medical context\n",
    "            if np.random.random() > 0.7:\n",
    "                prefixes = [\n",
    "                    \"Dermatological finding: \",\n",
    "                    \"Skin examination reveals: \",\n",
    "                    \"Clinical presentation: \",\n",
    "                    \"Visual diagnosis: \",\n",
    "                ]\n",
    "                text = np.random.choice(prefixes) + text\n",
    "\n",
    "        else:\n",
    "            # Consistent format for validation/test\n",
    "            text = f\"{row['condition']}: {description}\"\n",
    "\n",
    "        return text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Load image\n",
    "        image_path = self.images_dir / row['image_path']\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except:\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "\n",
    "        # Create fine-grained text\n",
    "        text = self.create_fine_grained_text(row)\n",
    "\n",
    "        # Process\n",
    "        inputs = self.processor(\n",
    "            text=text,\n",
    "            images=image,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=64,  # SigLIP uses 64 tokens max\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Remove batch dimension\n",
    "        for key in inputs:\n",
    "            inputs[key] = inputs[key].squeeze(0)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83983d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigLIPContrastiveModel(nn.Module):\n",
    "    \"\"\"SigLIP model for contrastive learning.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str, temperature: float = 0.07):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.temperature = temperature\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / temperature))\n",
    "\n",
    "    def forward(self, input_ids=None, pixel_values=None, attention_mask=None, **kwargs):\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            pixel_values=pixel_values,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "        image_embeds = outputs.vision_model_output.pooler_output\n",
    "        text_embeds = outputs.text_model_output.pooler_output\n",
    "\n",
    "        image_embeds = F.normalize(image_embeds, dim=-1)\n",
    "        text_embeds = F.normalize(text_embeds, dim=-1)\n",
    "\n",
    "        logit_scale = self.logit_scale.exp()\n",
    "        logits_per_image = logit_scale * image_embeds @ text_embeds.t()\n",
    "        logits_per_text = logits_per_image.t()\n",
    "\n",
    "        batch_size = image_embeds.shape[0]\n",
    "        labels = torch.arange(batch_size, device=image_embeds.device)\n",
    "\n",
    "        loss_i = F.cross_entropy(logits_per_image, labels)\n",
    "        loss_t = F.cross_entropy(logits_per_text, labels)\n",
    "        loss = (loss_i + loss_t) / 2\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits_per_image': logits_per_image,\n",
    "            'logits_per_text': logits_per_text,\n",
    "            'image_embeds': image_embeds,\n",
    "            'text_embeds': text_embeds,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b5d1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Loading Model and Creating Datasets\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded with 203,155,971 parameters\n",
      "✓ Datasets created\n",
      "  Train: 4136 samples\n",
      "  Val: 886 samples\n",
      "  Test: 887 samples\n",
      "\n",
      "Sample fine-grained texts:\n",
      "  [Inflicted skin lesions] Skin examination reveals: Medical condition: inflicted skin lesions. Skin lesion...\n",
      "  [Drug Rash] drug rash: Dermatoscopy image showing Drug Rash...\n",
      "  [Drug Rash] Skin examination reveals: drug rash, a type of urticaria/allergic...\n",
      "\n",
      "================================================================================\n",
      "STARTING FINE-GRAINED TRAINING\n",
      "================================================================================\n",
      "Training with fine-grained condition labels...\n",
      "Focus on discriminating between 66 specific conditions\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2861' max='3250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2861/3250 35:04 < 04:46, 1.36 it/s, Epoch 22/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.202500</td>\n",
       "      <td>2.916265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.659600</td>\n",
       "      <td>2.655604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.280300</td>\n",
       "      <td>2.640691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.814900</td>\n",
       "      <td>2.668144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.388000</td>\n",
       "      <td>2.712838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.123000</td>\n",
       "      <td>2.806437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>2.869214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.967100</td>\n",
       "      <td>2.897414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.909500</td>\n",
       "      <td>2.913833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.892200</td>\n",
       "      <td>2.949419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.875900</td>\n",
       "      <td>3.031486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.848700</td>\n",
       "      <td>3.063886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.840300</td>\n",
       "      <td>3.081568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.814200</td>\n",
       "      <td>3.076688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.823900</td>\n",
       "      <td>3.097188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.736900</td>\n",
       "      <td>3.126570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.687200</td>\n",
       "      <td>3.051169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.730500</td>\n",
       "      <td>3.065549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>3.133055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>3.144595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>3.095456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>3.120430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Loading Model and Creating Datasets\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(config.model_name)\n",
    "model = SigLIPContrastiveModel(config.model_name, config.temperature)\n",
    "model.to(config.device)\n",
    "\n",
    "print(f\"✓ Model loaded with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = FineGrainedContrastiveDataset(train_df, config.images_dir, processor, mode='train')\n",
    "val_dataset = FineGrainedContrastiveDataset(val_df, config.images_dir, processor, mode='val')\n",
    "test_dataset = FineGrainedContrastiveDataset(test_df, config.images_dir, processor, mode='test')\n",
    "\n",
    "print(f\"✓ Datasets created\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Val: {len(val_dataset)} samples\")\n",
    "print(f\"  Test: {len(test_dataset)} samples\")\n",
    "\n",
    "# Show sample texts\n",
    "print(\"\\nSample fine-grained texts:\")\n",
    "for i in range(3):\n",
    "    sample_text = train_dataset.create_fine_grained_text(train_df.iloc[i])\n",
    "    condition = train_df.iloc[i]['condition']\n",
    "    print(f\"  [{condition}] {sample_text[:80]}...\")\n",
    "\n",
    "\n",
    "# Custom trainer\n",
    "class ContrastiveTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs['loss']\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "        \"\"\"Custom prediction step for contrastive learning.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs['loss']\n",
    "\n",
    "        if prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "\n",
    "        return (loss, outputs['logits_per_image'].cpu(), None)\n",
    "\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(config.output_dir),\n",
    "    num_train_epochs=config.num_epochs,\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    per_device_eval_batch_size=config.batch_size,\n",
    "    learning_rate=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    "    warmup_steps=config.warmup_steps,\n",
    "    fp16=config.fp16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_num_workers=0,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = ContrastiveTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING FINE-GRAINED TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(\"Training with fine-grained condition labels...\")\n",
    "print(\"Focus on discriminating between 66 specific conditions\")\n",
    "print()\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(f\"\\n✓ Training complete! Final loss: {train_result.training_loss:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(f\"✓ Test loss: {test_results['eval_loss']:.4f}\")\n",
    "\n",
    "# Save\n",
    "final_path = config.output_dir / 'final_model'\n",
    "trainer.save_model(str(final_path))\n",
    "processor.save_pretrained(str(final_path))\n",
    "print(f\"✓ Model saved to: {final_path}\")\n",
    "\n",
    "\n",
    "# Test retrieval\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Testing Fine-Grained Retrieval\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def test_retrieval(model, processor, test_df, images_dir, n_samples=20):\n",
    "    \"\"\"Test fine-grained retrieval capabilities.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    sample_indices = np.random.choice(len(test_df), min(n_samples, len(test_df)), replace=False)\n",
    "\n",
    "    accuracies = []\n",
    "    condition_accuracies = {}\n",
    "\n",
    "    for idx in tqdm(sample_indices, desc=\"Testing retrieval\"):\n",
    "        row = test_df.iloc[idx]\n",
    "\n",
    "        # Load image\n",
    "        image_path = images_dir / row['image_path']\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Create text options - use different conditions\n",
    "        correct_text = f\"{row['condition']}: {row['description']}\"\n",
    "        correct_condition = row['condition']\n",
    "\n",
    "        # Get distractors from different conditions\n",
    "        other_conditions = test_df[test_df['condition'] != correct_condition]['condition'].unique()\n",
    "        distractor_conditions = np.random.choice(\n",
    "            other_conditions,\n",
    "            min(9, len(other_conditions)),\n",
    "            replace=False\n",
    "        )\n",
    "\n",
    "        distractor_texts = []\n",
    "        for dist_cond in distractor_conditions:\n",
    "            dist_row = test_df[test_df['condition'] == dist_cond].iloc[0]\n",
    "            distractor_texts.append(f\"{dist_row['condition']}: {dist_row['description']}\")\n",
    "\n",
    "        all_texts = [correct_text] + distractor_texts\n",
    "\n",
    "        # Process\n",
    "        inputs = processor(\n",
    "            text=all_texts,\n",
    "            images=[image] * len(all_texts),\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=64,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(config.device)\n",
    "\n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            similarities = outputs['logits_per_image'][0]\n",
    "\n",
    "        # Check accuracy\n",
    "        predicted_idx = similarities.argmax().item()\n",
    "        correct = predicted_idx == 0\n",
    "        accuracies.append(correct)\n",
    "\n",
    "        # Track per-condition accuracy\n",
    "        if correct_condition not in condition_accuracies:\n",
    "            condition_accuracies[correct_condition] = []\n",
    "        condition_accuracies[correct_condition].append(correct)\n",
    "\n",
    "    accuracy = np.mean(accuracies)\n",
    "    print(f\"\\n✓ Fine-grained retrieval accuracy: {accuracy:.2%}\")\n",
    "\n",
    "    # Show per-condition performance\n",
    "    print(\"\\nPer-condition accuracy (samples with data):\")\n",
    "    for condition, accs in sorted(condition_accuracies.items()):\n",
    "        if len(accs) >= 1:\n",
    "            cond_acc = np.mean(accs)\n",
    "            print(f\"  {condition:35s}: {cond_acc:6.2%} (n={len(accs)})\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "retrieval_acc = test_retrieval(model, processor, test_df, config.images_dir)\n",
    "\n",
    "# Save summary\n",
    "summary = {\n",
    "    'approach': 'fine_grained',\n",
    "    'num_conditions': int(df['condition'].nunique()),\n",
    "    'train_samples': len(train_df),\n",
    "    'final_loss': float(train_result.training_loss),\n",
    "    'test_loss': float(test_results['eval_loss']),\n",
    "    'retrieval_accuracy': float(retrieval_acc),\n",
    "}\n",
    "\n",
    "with open(config.output_dir / 'training_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINE-GRAINED TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAdvantages of fine-grained approach:\")\n",
    "print(\"  • Direct discrimination between 66 specific conditions\")\n",
    "print(\"  • No hierarchical complexity\")\n",
    "print(\"  • Focused on exact condition matching\")\n",
    "print(\"  • Should improve retrieval accuracy\")\n",
    "print(f\"\\nFinal metrics:\")\n",
    "print(f\"  Test loss: {test_results['eval_loss']:.4f}\")\n",
    "print(f\"  Retrieval accuracy: {retrieval_acc:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health-kiosk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
