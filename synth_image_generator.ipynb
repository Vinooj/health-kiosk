{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ccb750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Install and Import Dependencies\n",
    "# !pip install scikit-image\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from skimage import filters\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'MODEL_ID': \"google/siglip-base-patch16-224\",\n",
    "    'OUTPUT_DIR': \"./siglip-scin-full-3000\", # ./siglip-scin-lora\",\n",
    "    'DATA_DIR': \"./data/scin_cache\",  # Local cache directory\n",
    "    'BATCH_SIZE': 16,\n",
    "    'LEARNING_RATE': 5e-5, # 1e-4 before\n",
    "    'LORA_RANK': 32,\n",
    "    'LORA_ALPHA': 32,\n",
    "    'MAX_STEPS': 3000,\n",
    "    'LOSS_TYPE': \"sigmoid\",  # or \"contrastive\"\n",
    "    'N_VAL_SAMPLES': 1000,\n",
    "    'N_TRAIN_SAMPLES': 5000,  # Set to None to use all available\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8f2dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Define Custom Augmentations\n",
    "\n",
    "class GaussianNoise:\n",
    "    \"\"\"Adds Gaussian noise to a PIL Image.\"\"\"\n",
    "    def __init__(self, mean=0., std=0.1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL Image to float numpy array (0-1)\n",
    "        np_img = np.array(img).astype(np.float32) / 255.0\n",
    "        # Generate noise\n",
    "        noise = np.random.normal(self.mean, self.std, np_img.shape)\n",
    "        # Add noise and clip\n",
    "        noisy_img = np.clip(np_img + noise, 0, 1)\n",
    "        # Convert back to PIL Image\n",
    "        return Image.fromarray((noisy_img * 255).astype(np.uint8))\n",
    "\n",
    "class SobelFilter:\n",
    "    \"\"\"Applies a Sobel filter to a PIL Image.\"\"\"\n",
    "    def __call__(self, img):\n",
    "        # Convert to numpy array\n",
    "        np_img = np.array(img)\n",
    "        \n",
    "        # Convert to grayscale if it's RGB\n",
    "        if len(np_img.shape) == 3:\n",
    "            np_img = rgb2gray(np_img)\n",
    "            \n",
    "        # Apply Sobel filter\n",
    "        sobel_img = filters.sobel(np_img)\n",
    "        \n",
    "        # Normalize to 0-1 range\n",
    "        sobel_img = (sobel_img - np.min(sobel_img)) / (np.max(sobel_img) - np.min(sobel_img) + 1e-6)\n",
    "        \n",
    "        # Convert to 0-255 uint8\n",
    "        sobel_img = (sobel_img * 255).astype(np.uint8)\n",
    "        \n",
    "        # Stack to 3 channels to mimic RGB for the model\n",
    "        return Image.fromarray(np.stack([sobel_img]*3, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic data in: ./data/synthetic\n",
      "Loading source data from: ./data/scin_cache/train_5000.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell: Generation Script (Corrected)\n",
    "\n",
    "# --- 1. Define Configuration ---\n",
    "OUTPUT_SYNTHETIC_DIR = \"./data/synthetic\"\n",
    "IMG_DIR = os.path.join(OUTPUT_SYNTHETIC_DIR, \"images\")\n",
    "METADATA_FILE = os.path.join(OUTPUT_SYNTHETIC_DIR, \"labels.csv\")\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(IMG_DIR, exist_ok=True)\n",
    "\n",
    "# Try to get image size from CONFIG, default to 224\n",
    "try:\n",
    "    IMG_SIZE = 224 # Default\n",
    "    if 'CONFIG' in locals() or 'CONFIG' in globals():\n",
    "        # Assuming 224 from \"google/siglip-base-patch16-224\"\n",
    "        pass \n",
    "except NameError:\n",
    "    IMG_SIZE = 224\n",
    "\n",
    "# --- 2. Define Augmentation Pipelines ---\n",
    "# (This section is unchanged, assuming it's in the same cell)\n",
    "aug_pipelines = {\n",
    "    \"crop_resize\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.5, 1.0)),\n",
    "    ]),\n",
    "    \"crop_resize_flip\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.5, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "    ]),\n",
    "    \"color_distort\": transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
    "        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    ]),\n",
    "    \"sobel\": transforms.Compose([\n",
    "        SobelFilter(),\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    ]),\n",
    "    \"blur\": transforms.Compose([\n",
    "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    ]),\n",
    "    \"noise\": transforms.Compose([\n",
    "        GaussianNoise(mean=0., std=0.05),\n",
    "        transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
    "    ])\n",
    "}\n",
    "\n",
    "# --- 3. Run Generation Loop ---\n",
    "print(f\"Generating synthetic data in: {OUTPUT_SYNTHETIC_DIR}\")\n",
    "\n",
    "# **** START FIX ****\n",
    "# Manually load the train_data from the cache file\n",
    "import pickle\n",
    "train_cache_path = None  # Define variable before the try block\n",
    "try:\n",
    "    # This line *requires* CONFIG to be defined\n",
    "    if 'CONFIG' not in locals() and 'CONFIG' not in globals():\n",
    "        raise NameError(\"name 'CONFIG' is not defined. Please run Cell 1 first.\")\n",
    "        \n",
    "    train_cache_path = os.path.join(CONFIG['DATA_DIR'], f\"train_{CONFIG['N_TRAIN_SAMPLES']}.pkl\")\n",
    "    print(f\"Loading source data from: {train_cache_path}\")\n",
    "    \n",
    "    with open(train_cache_path, \"rb\") as f:\n",
    "        source_data = pickle.load(f)\n",
    "    \n",
    "    if not source_data:\n",
    "        raise FileNotFoundError(\"Source data file is empty\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR: Could not load source data.\")\n",
    "    if train_cache_path:\n",
    "        print(f\"  Attempted path: {train_cache_path}\")\n",
    "    print(\"  Please ensure you have run Cell 1 (to define CONFIG) and Cell 2 (to cache the dataset).\")\n",
    "    print(f\"  Error details: {e}\")\n",
    "    # Stop execution if we can't load the data\n",
    "    raise e\n",
    "# **** END FIX ****\n",
    "\n",
    "image_counter = 0\n",
    "metadata_rows = []\n",
    "\n",
    "for transform_name, transform_pipeline in aug_pipelines.items():\n",
    "    print(f\"Applying transform: {transform_name}\")\n",
    "    \n",
    "    for item in tqdm(source_data, desc=f\"Generating {transform_name}\"):\n",
    "        original_image = item['image']\n",
    "        label = item['text']\n",
    "        \n",
    "        try:\n",
    "            augmented_image = transform_pipeline(original_image)\n",
    "            filename = f\"aug_{transform_name}_{image_counter:07d}.png\"\n",
    "            save_path = os.path.join(IMG_DIR, filename)\n",
    "            augmented_image.save(save_path)\n",
    "            metadata_rows.append([filename, label])\n",
    "            image_counter += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Skipping image due to error: {e}\")\n",
    "\n",
    "# --- 4. Save Metadata CSV ---\n",
    "print(f\"\\nSaving metadata to {METADATA_FILE}...\")\n",
    "with open(METADATA_FILE, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"image_file\", \"label\"]) # Write header\n",
    "    writer.writerows(metadata_rows)\n",
    "\n",
    "print(f\"\\nDone! Generated {image_counter} new images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce344db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: New Dataset Class for loading synthetic data\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "class SyntheticDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class to load the synthetic data \n",
    "    we just saved to disk.\n",
    "    \"\"\"\n",
    "    def __init__(self, metadata_file, img_dir):\n",
    "        print(f\"Loading metadata from: {metadata_file}\")\n",
    "        # Load the CSV file\n",
    "        self.metadata = pd.read_csv(metadata_file)\n",
    "        self.img_dir = img_dir\n",
    "        print(f\"Found {len(self.metadata)} images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the filename and label for the given index\n",
    "        row = self.metadata.iloc[idx]\n",
    "        filename = row['image_file']\n",
    "        label = row['label']\n",
    "        \n",
    "        # Construct the full image path\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            # Open the image, convert to RGB\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}, returning None. Error: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Return in the same format as your original dataset\n",
    "        return {\"image\": image, \"text\": label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8257bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Example of how to combine datasets ---\n",
    "\n",
    "# 1. Initialize your new dataset\n",
    "synthetic_dataset = SyntheticDataset(\n",
    "    metadata_file=METADATA_FILE, \n",
    "    img_dir=IMG_DIR\n",
    ")\n",
    "\n",
    "# 2. Get your original dataset (assuming 'train_dataset' exists)\n",
    "original_dataset = Path(CONFIG['DATA_DIR']) / f\"train_{n_train}.pkl\"\n",
    "\n",
    "# 3. Combine them\n",
    "# from torch.utils.data import ConcatDataset\n",
    "combined_train_dataset = ConcatDataset([original_dataset, synthetic_dataset])\n",
    "\n",
    "# 4. Use this combined dataset in your Trainer\n",
    "# print(f\"Total training samples: {len(combined_train_dataset)}\")\n",
    "# trainer = CustomTrainer(\n",
    "#     ...\n",
    "#     train_dataset=combined_train_dataset, # <-- Use the combined data\n",
    "#     ...\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health-kiosk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
